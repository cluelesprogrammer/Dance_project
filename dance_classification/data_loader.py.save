import datasets.dataset as dataset
from torchvision import transforms, utils
import torch
from torch.utils.data import DataLoader
import pandas as pd

def concatenated_dataloaders(img_size, batch_size, limb_width, sigma, normalize, rotation):
	lets_dance_train_mean, lets_dance_train_std = [0.4100, 0.3402, 0.3244], [0.2834, 0.2593, 0.2477]
	lets_dance_val_mean, lets_dance_val_std = [0.4105, 0.3408, 0.3253], [0.2834, 0.2595, 0.2479]
	transform_coco_train, transform_mpii_train, transform_lets_dance_train, transform_coco_val, transform_lets_dance_val = {}, {}, {}, {}
	if (normalize):
		transform_coco_train['image'] = transforms.Normalize(mean=[0.4634, 0.4463, 0.4182], std=[0.2777, 0.2724, 0.2863])
		transform_coco_val['image'] = transforms.Normalize(mean=[0.4627, 0.4454, 0.4162], std=[0.2789, 0.2737, 0.2862])
		transform_mpii_train['image'] = transforms.Normalize(mean=[0.4680, 0.4497, 0.4127], std=[0.2715, 0.2671, 0.2712])
		transform_lets_dance_train['image'] = transforms.Normalize(mean=lets_dance_train_mean, std=lets_dance_train_std)
		transform_lets_dance_val['image'] = transforms.Normalize(mean=val_mean, std=val_std)

	coco_train_dataset = dataset.COCODataset('./data/coco', 'train', img_size,  limb_width, sigma, transform=transform_coco_train, rot=bool(rotation))
	mpii_train_dataset  = dataset.MPIIDataset('./data/MPII', './data/MPII/annotations.mat', load_size, limb_width, sigma, transform=transform_mpii_train, rot=False)
	lets_dance_train_dataset = dataset.DanceDataset(pd.read_csv('./data/letsdance/train.csv'), img_size, limb_width, sigma,transform=transform_train, rot=rotation)
	concat_train_dataset = torch.utils.data.ConcatDataset([coco_train_dataset, mpii_train_dataset,lets_dance_train_dataset])
	dataloaders = {}
	dataloaders['train'] = Dataloader(concat_train_dataset, batch_size=batch_size, num_workers=11, shuffle=True, pin_memory=True)

	

	return 

def all_val_dataloaders(

"""
class coco_mpii_lets_dance_dataloaders():
	def __init__(self, img_size, batch_size, limb_width, sigma, normalize, rotation):
		self.coco_mpii_loaders = coco_mpii_loaders(img_size, batch_size, limb_width, sigma, normalize, rotation)
		self.lets_dance_loaders = lets_dance_loaders(img_size, batch_size, limb_width, sigma, normalize, rotation)
		self.train_called_index = torch.zeros(self.val_len())
		self.val_called_index = torch.zero(self.train_len())
	def train_batch(self, idx):
		self.train_called_index[idx] = 1
		
	def val_batch(self, idx):

	def train_len(self):
		return len(self.coco_mpii_loaders['coco_train']) + len(self.coco_mpii_loaders['mpii_train']) + len(self.lets_dance_loaders['train'])
	def val_len(self):
		return len(self.coco_mpii_loaders['coco_val']) + len(self.lets_dance_loaders['val'])
"""
def coco_mpii_loaders(img_size, batch_size, limb_width, sigma, normalize, rotation):
	transform_mpii_train, transform_coco_train, transform_coco_val = {}, {}, {}
	if (normalize == 1):
		#transforms.Normalize(mean=[0.2679, 0.2126, 0.2496], std=[0.2720, 0.2717, 0.2675])
		transform_mpii_train['image'] = transforms.Normalize(mean=[0.4680, 0.4497, 0.4127], std=[0.2715, 0.2671, 0.2712])
		transform_coco_train['image'] = transforms.Normalize(mean=[0.4634, 0.4463, 0.4182], std=[0.2777, 0.2724, 0.2863])
		transform_coco_val['image'] = transforms.Normalize(mean=[0.4627, 0.4454, 0.4162], std=[0.2789, 0.2737, 0.2862])
	datasets = {}
	datasets['coco_train'] = dataset.COCODataset('./data/coco', 'train', img_size,  limb_width, sigma, transform=transform_coco_train, rot=bool(rotation))
	datasets['coco_val'] = dataset.COCODataset('./data/coco', 'val', img_size, limb_width, sigma, transform=transform_coco_val, rot=bool(rotation))
	datasets['mpii_train'] = dataset.MPIIDataset('./data/MPII', './data/MPII/annotations.mat', img_size, limb_width, sigma, transform=transform_mpii_train, rot=bool(rotation))
	dataloaders = {}
	for k in datasets:
		dataloaders[k] = DataLoader(datasets[k], batch_size=batch_size, num_workers=11, shuffle=True, pin_memory=True)
	return dataloaders

def mpii_loaders(img_size, batch_size, limb_width, sigma, normalize, rotation):
	transform_mpii = {}
	if (normalize):
		transform_mpii['image'] = transforms.Normalize(mean=[0.4680, 0.4497, 0.4127], std=[0.2715, 0.2671, 0.2712])
	dataloaders = {}
	for k in datasets:
		dataloaders[k] = DataLoader(datasets[k], batch_size=batch_size, num_workers=11, shuffle=True, pin_memory=True)
	return dataloaders


def coco_loaders(img_size, batch_size, limb_width, sigma, normalize, rotation):
	transform_coco_train, transform_coco_val = {}, {}
	if (normalize == 1):
		transform_coco_train['image'] = transforms.Normalize(mean=[0.4634, 0.4463, 0.4182], std=[0.2777, 0.2724, 0.2863])
		transform_coco_val['image'] = transforms.Normalize(mean=[0.4627, 0.4454, 0.4162], std=[0.2789, 0.2737, 0.2862])
	datasets = {}
	datasets['coco_train'] = dataset.COCODataset('./data/coco', 'train', img_size,  limb_width, sigma, transform=transform_coco_train, rot=bool(rotation))
	datasets['coco_val'] = dataset.COCODataset('./data/coco', 'val', img_size, limb_width, sigma, transform=transform_coco_val, rot=bool(rotation))
	dataloaders = {}
	for k in datasets:
		dataloaders[k] = DataLoader(datasets[k], batch_size=batch_size, num_workers=11, shuffle=True, pin_memory=True)
	return dataloaders


def lets_dance_loaders(img_size, batch_size, limb_width, sigma, normalize, rotation):
		transform_train, transform_val, transform_test = {}, {}, {}
		train_pd, val_pd, test_pd = pd.read_csv('./data/letsdance/train.csv'), pd.read_csv('./data/letsdance/val.csv'), pd.read_csv('./data/letsdance/test.csv')
		means, stds = {}, {}
		train_mean, train_std = [0.4100, 0.3402, 0.3244], [0.2834, 0.2593, 0.2477]
		val_mean, val_std = [0.4105, 0.3408, 0.3253], [0.2834, 0.2595, 0.2479]
		test_mean, test_std = [0.4113, 0.3412, 0.3255], [0.2835, 0.2595, 0.2479]
		if (normalize == 1):
				transform_train['image'] = transforms.Normalize(mean=train_mean, std=train_std)
				transform_val['image'] = transforms.Normalize(mean=val_mean, std=val_std)
				transform_test['image'] = transforms.Normalize(mean=test_mean, std=test_std)
		train_data, test_data, val_data = dataset.DanceDataset(train_pd, img_size, limb_width, sigma,transform=transform_train, rot=rotation), \
										dataset.DanceDataset(test_pd, img_size, limb_width, sigma,transform=transform_test, rot=rotation), \
										dataset.DanceDataset(val_pd, img_size, limb_width, sigma,transform=transform_val, rot=rotation)
		dataloaders = {}
		dataloaders['train'] = DataLoader(train_data, batch_size=batch_size, num_workers=11, shuffle=True, pin_memory=True)
		dataloaders['val'] = DataLoader(val_data, batch_size=batch_size, num_workers=11, shuffle=True, pin_memory=True)
		dataloaders['test'] = DataLoader(test_data, batch_size=batch_size, num_workers=11, shuffle=True, pin_memory=True)
		return dataloaders
