import datasets.dataset as dataset
from torchvision import transforms, utils
import torch
from torch.utils.data import DataLoader, Subset
import pandas as pd

def concatenated_dataloaders(load_size, return_size, batch_size, limb_width, sigma, normalize):
	lets_dance_train_mean, lets_dance_train_std = [0.4100, 0.3402, 0.3244], [0.2834, 0.2593, 0.2477]
	lets_dance_val_mean, lets_dance_val_std = [0.4105, 0.3408, 0.3253], [0.2834, 0.2595, 0.2479]
	transform_coco_train, transform_mpii_train, transform_lets_dance_train, transform_coco_val, transform_lets_dance_val = {}, {}, {}, {}, {}
	if (normalize):
		transform_coco_train['image'] = transforms.Compose([transforms.Normalize(mean=[0.4634, 0.4463, 0.4182], std=[0.2777, 0.2724, 0.2863]), transforms.RandomGrayscale()])
		transform_coco_val['image'] = transforms.Compose([transforms.Normalize(mean=[0.4627, 0.4454, 0.4162], std=[0.2789, 0.2737, 0.2862]), transforms.RandomGrayscale()])
		transform_mpii_train['image'] = transforms.Compose([transforms.Normalize(mean=[0.4680, 0.4497, 0.4127], std=[0.2715, 0.2671, 0.2712]), transforms.RandomGrayscale()])
		transform_lets_dance_train['image'] = transforms.Compose([transforms.Normalize(mean=lets_dance_train_mean, std=lets_dance_train_std), transforms.RandomGrayscale()])
		transform_lets_dance_val['image'] = transforms.Compose([transforms.Normalize(mean=lets_dance_val_mean, std=lets_dance_val_std), transforms.RandomGrayscale()])
	coco_train_dataset = dataset.COCODataset('./data/coco', 'train', load_size, return_size, limb_width, sigma, transform=transform_coco_train)
	coco_val_dataset = dataset.COCODataset('./data/coco', 'val', load_size, return_size, limb_width, sigma, transform=transform_coco_val)
	mpii_train_dataset  = dataset.MPIIDataset('./data/MPII', './data/MPII/annotations.mat', load_size, return_size, limb_width, sigma, transform=transform_mpii_train)
	lets_dance_train_dataset = dataset.DanceDataset(pd.read_csv('./data/letsdance/train.csv'), load_size, return_size, limb_width, sigma,transform=transform_lets_dance_train)
	lets_dance_val_dataset = dataset.DanceDataset(pd.read_csv('./data/letsdance/val.csv'), load_size, return_size, limb_width, sigma,transform=transform_lets_dance_val)
	print('lets dance val length', len(lets_dance_val_dataset))
	lets_dance_test_dataset = dataset.DanceDataset(pd.read_csv('./data/letsdance/test.csv'), load_size, return_size, limb_width, sigma,transform=transform_lets_dance_val)
	print('lets dance dataset test length', len(lets_dance_test_dataset))

	concat_train_dataset = torch.utils.data.ConcatDataset([coco_train_dataset, mpii_train_dataset,lets_dance_train_dataset])
	concat_val_dataset = torch.utils.data.ConcatDataset([coco_val_dataset, lets_dance_val_dataset])
	dataloaders = {}
	dataloaders['train'] = DataLoader(concat_train_dataset, batch_size=batch_size, num_workers=6, shuffle=True, pin_memory=True)
	dataloaders['val'] = DataLoader(concat_val_dataset, batch_size=batch_size, num_workers=6, shuffle=True, pin_memory=True)
	#dataloaders['coco_val'] = DataLoader(coco_val_dataset, batch_size=batch_size, num_workers=11, shuffle=True, pin_memory=True)
	#dataloaders['lets_dance_val'] = DataLoader(lets_dance_val_dataset, batch_size=batch_size, num_workers=11, shuffle=True, pin_memory=True)
	return dataloaders

def dance_video_dataloader(return_size, batch_size, normalize):
	mean, std = [0.4100, 0.3402, 0.3244], [0.2834, 0.2593, 0.2477]
	transform = transforms.Compose([transforms.Normalize(mean=mean, std=std), transforms.RandomGrayScale(), transforms.ColorJitter()])
	train_val_df, test_df = pd.read_csv('./data/letsdance/vdo_train_val.csv'), pd.read_csv('./data/letsdance/vdo_test.csv')
	train_val_dataset, test_dataset = dataset.DanceVideoDataset(384, transform=transform), dataset.DanceVideoDatset(384, test_df, transform=transform)
	train_split, val_split = 0.80, 0.20

	train_
	train_subset, val_subset = Subset(vdo_dataset, train_id), Subset(vdo_dataset, val_id)
	dataloaders = {}

"""
def concatenated_dataloaders(img_size, batch_size, limb_width, sigma, normalize, rotation):


class coco_mpii_lets_dance_dataloaders():
	def __init__(self, img_size, batch_size, limb_width, sigma, normalize, rotation):
		self.coco_mpii_loaders = coco_mpii_loaders(img_size, batch_size, limb_width, sigma, normalize, rotation)
		self.lets_dance_loaders = lets_dance_loaders(img_size, batch_size, limb_width, sigma, normalize, rotation)
		self.train_called_index = torch.zeros(self.val_len())
		self.val_called_index = torch.zero(self.train_len())
	def train_batch(self, idx):
		self.train_called_index[idx] = 1
	def val_batch(self, idx):

	def train_len(self):
		return len(self.coco_mpii_loaders['coco_train']) + len(self.coco_mpii_loaders['mpii_train']) + len(self.lets_dance_loaders['train'])
	def val_len(self):
		return len(self.coco_mpii_loaders['coco_val']) + len(self.lets_dance_loaders['val'])
"""

def coco_mpii_loaders(load_size, return_size, batch_size, limb_width, sigma, normalize):
	transform_mpii_train, transform_coco_train, transform_coco_val = {}, {}, {}
	if (normalize):
		#transforms.Normalize(mean=[0.2679, 0.2126, 0.2496], std=[0.2720, 0.2717, 0.2675])
		transform_mpii_train['image'] = transforms.Compose([transforms.Normalize(mean=[0.4680, 0.4497, 0.4127], std=[0.2715, 0.2671, 0.2712]), transforms.RandomGrayscale()])
		transform_coco_train['image'] = transforms.Compose([transforms.Normalize(mean=[0.4634, 0.4463, 0.4182], std=[0.2777, 0.2724, 0.2863]), transforms.RandomGrayscale()])
		transform_coco_val['image'] = transforms.Normalize(mean=[0.4627, 0.4454, 0.4162], std=[0.2789, 0.2737, 0.2862])
	datasets = {}
	coco_train_dataset = dataset.COCODataset('./data/coco', 'train', load_size, return_size, limb_width, sigma, transform=transform_coco_train)
	coco_val_dataset = dataset.COCODataset('./data/coco', 'val', load_size, return_size, limb_width, sigma, transform=transform_coco_val)
	mpii_train_dataset = dataset.MPIIDataset('./data/MPII', './data/MPII/annotations.mat', load_size, return_size, limb_width, sigma, transform=transform_mpii_train)
	coco_mpii_train = torch.utils.data.ConcatDataset([coco_train_dataset, mpii_train_dataset])
	dataloaders = {}
	dataloaders['train'] = DataLoader(coco_mpii_train, batch_size=batch_size, num_workers=6, shuffle=True, pin_memory=True)
	dataloaders['val'] = DataLoader(coco_val_dataset, batch_size=batch_size, num_workers=6, shuffle=True, pin_memory=True)
	"""
	dataloaders = {}
	for k in datasets:
		dataloaders[k] = DataLoader(datasets[k], batch_size=batch_size, num_workers=11, shuffle=True, pin_memory=True)
	"""
	return dataloaders

def mpii_loaders(load_size, return_size, batch_size, limb_width, sigma, normalize):
	transform_mpii = {}
	if (normalize):
		transform_mpii['image'] = transforms.Normalize(mean=[0.4680, 0.4497, 0.4127], std=[0.2715, 0.2671, 0.2712])
	dataloaders = {}
	for k in datasets:
		dataloaders[k] = DataLoader(datasets[k], batch_size=batch_size, num_workers=11, shuffle=True, pin_memory=True)
	return dataloaders



def coco_loaders(load_size, return_size, batch_size, limb_width, sigma, normalize):
	transform_coco_train, transform_coco_val = {}, {}
	if (normalize == 1):
		transform_coco_train['image'] = transforms.Compose([transforms.Normalize(mean=[0.4634, 0.4463, 0.4182], std=[0.2777, 0.2724, 0.2863]), transforms.RandomGrayscale(),transforms.ColorJitter()])
		transform_coco_val['image'] = transforms.Compose([transforms.Normalize(mean=[0.4627, 0.4454, 0.4162], std=[0.2789, 0.2737, 0.2862]), transforms.RandomGrayscale(), transforms.ColorJitter()])
	datasets = {}
	datasets['train'] = dataset.COCODataset('./data/coco', 'train', load_size, return_size, limb_width, sigma, transform=transform_coco_train)
	datasets['val'] = dataset.COCODataset('./data/coco', 'val', load_size, return_size, limb_width, sigma, transform=transform_coco_val)
	dataloaders = {}
	for k in datasets:
		dataloaders[k] = DataLoader(datasets[k], batch_size=batch_size, num_workers=11, shuffle=True, pin_memory=True)
	return dataloaders


def lets_dance_loaders(load_size, return_size, batch_size, limb_width, sigma, normalize):
		transform_train, transform_val, transform_test = {}, {}, {}
		train_pd, val_pd, test_pd = pd.read_csv('./data/letsdance/train.csv'), pd.read_csv('./data/letsdance/val.csv'), pd.read_csv('./data/letsdance/test.csv')
		means, stds = {}, {}
		train_mean, train_std = [0.4100, 0.3402, 0.3244], [0.2834, 0.2593, 0.2477]
		val_mean, val_std = [0.4105, 0.3408, 0.3253], [0.2834, 0.2595, 0.2479]
		test_mean, test_std = [0.4113, 0.3412, 0.3255], [0.2835, 0.2595, 0.2479]
		if (normalize == 1):
				transform_train['image'] = transforms.Compose([transforms.Normalize(mean=train_mean, std=train_std), transforms.RandomGrayscale()])
				transform_val['image'] = transforms.Compose([transforms.Normalize(mean=val_mean, std=val_std), transforms.RandomGrayscale()])
				transform_test['image'] = transforms.Compose([transforms.Normalize(mean=test_mean, std=test_std), transforms.RandomGrayscale()])
		train_data, test_data, val_data = dataset.DanceDataset(train_pd, load_size, return_size, limb_width, sigma,transform=transform_train), \
										dataset.DanceDataset(test_pd, load_size, return_size, limb_width, sigma,transform=transform_test), \
										dataset.DanceDataset(val_pd, load_size, return_size, limb_width, sigma,transform=transform_val)
		dataloaders = {}
		dataloaders['train'] = DataLoader(train_data, batch_size=batch_size, num_workers=11, shuffle=True, pin_memory=True)
		dataloaders['val'] = DataLoader(val_data, batch_size=batch_size, num_workers=11, shuffle=True, pin_memory=True)
		dataloaders['test'] = DataLoader(test_data, batch_size=batch_size, num_workers=11, shuffle=True, pin_memory=True)
		return dataloaders
