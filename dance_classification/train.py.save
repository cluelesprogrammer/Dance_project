import torch
import numpy as np
import time
import argparse
import wandb
import yaml
from tqdm import tqdm
from loss import paf_loss, conf_loss
from data_loader import lets_dance_loaders, coco_mpii_loaders, concatenated_dataloaders
from models_loader import get_model
from datasets.dataset import GroundTruthGenerator as G
import torch.optim as optim
import math

def train_epoch(model, optimizers, schedulers, dataloader, device, cosine_annealing=False, epoch=-1, test=False):
	model.train()
	n_batches_loss, n_batches_paf_loss, n_batches_conf_loss, log_freq = 0.0, 0.0, 0.0, 100
	i = 0
	for batch in tqdm(dataloader):
		images, paf_truths, conf_truths, paf_mask, conf_mask = batch['image'].float().to(device), batch['pafs'].float().to(device), batch['confs'].float().to(device), batch['paf_mask'][0].to(device), batch['conf_mask'][0].to(device)
		for opt in optimizers:
			opt.zero_grad()
		paf_preds, conf_preds = model(images)
		paf_l, conf_l = paf_loss(paf_preds, paf_truths, paf_mask=paf_mask), conf_loss(conf_preds, conf_truths, conf_mask=conf_mask)
		loss = torch.sum(paf_l) + torch.sum(conf_l)
		#n_batches_loss += loss.clone().detach().item()
		#n_batches_paf_loss += torch.sum(paf_l.clone().detach()).item()
		#n_batches_conf_loss += torch.sum(conf_l.clone().detach()).item()
		model_order = ['ftrs', 'paf', 'conf']
		for o in optimizers:
			lr_dict = {}
			for i, p in enumerate(o.param_groups):
				lr_dict['{}_lr'.format(model_order[i])] = p['lr']
			wandb.log(lr_dict)
		wandb.log({'loss': loss.item()})
		wandb.log({'paf loss': torch.sum(paf_l).item()})
		wandb.log({'conf loss': torch.sum(conf_l).item()})
		"""
		if ((i+1) % log_freq == 0):
			log_loss = {}
			log_loss['rolling_avg_loss_last_{}_batches'.format(log_freq)] = loss.item()
			log_loss['rolling_avg_paf_loss_last_{}_batches'.format(log_freq)] = torch.sum(paf_l).item()
			log_loss['rolling_avg_conf_loss_last_{}_batches'.format(log_freq)] = torch.sum(conf_l).item()
			wandb.log(log_loss)
			n_batches_loss, n_batches_paf_loss, n_batches_conf_loss = 0.0, 0.0, 0.0
		"""
		loss.backward()
		for opt in optimizers:
			opt.step()
		for sch in schedulers:
			if (sch):
				sch.step()
		i += 1
		if (test):
			break

def val_epoch(mod, dataloader, device, epoch, test=False):
	mod.eval()
	running_loss = 0.0
	paf_losses, conf_losses = [], []
	running_paf_loss = 0.0
	running_conf_loss = 0.0
	for batch in tqdm(dataloader):
		images, paf_truths, conf_truths = batch['image'].to(device), batch['pafs'].to(device), batch['confs'].to(device)
		with torch.no_grad():
			paf_preds, conf_preds = mod(images)
		paf_l, conf_l = paf_loss(paf_preds, paf_truths), conf_loss(conf_preds, conf_truths)
		paf_losses.append(paf_l)
		conf_losses.append(conf_l)
		loss = torch.sum(paf_l) + torch.sum(conf_l)
		running_loss += loss.item()
		running_paf_loss += torch.sum(paf_l).item()
		running_conf_loss += torch.sum(conf_l).item()
		if (test):
			break
	stage_mean_paf_loss, stage_mean_conf_loss = torch.mean(torch.stack(paf_losses), dim=0), torch.mean(torch.stack(conf_losses), dim=0)
	data_paf_loss = [[layer, stage_paf_loss] for (layer, stage_paf_loss) in enumerate(stage_mean_paf_loss)]
	paf_table = wandb.Table(data=data_paf_loss, columns = ["layer", "layer_paf_loss"])
	paf_title = "paf_stage_per_batch_loss_epoch_{}".format(epoch)
	conf_title = "conf_stage_per_batch_loss_epoch_{}".format(epoch)
	wandb.log({paf_title: wandb.plot.line(paf_table, "layer", "layer_paf_loss", title=paf_title)})
	data_conf_loss = [[layer, stage_conf_loss] for (layer, stage_conf_loss) in enumerate(stage_mean_conf_loss)]
	conf_table = wandb.Table(data=data_conf_loss, columns = ["layer", "layer_conf_loss"])
	wandb.log({conf_title: wandb.plot.line(conf_table, "layer", "layer_conf_loss", title=conf_title)})
	wandb.log({'epoch':epoch, 'running_val_loss':running_loss, 'running_val_paf_loss':running_paf_loss, 'running_conf_val_loss':running_conf_loss})
	return running_loss / len(dataloader), running_paf_loss / len(dataloader), running_conf_loss / len(dataloader)
	"""
	data_conf_loss = [[layer, layer_conf_loss] for (layer, layer_paf_loss) in enumerate(layerwise_mean_paf_loss)]
	for i, l in enumerate(layerwise_mean_paf_loss):
	wandb.log({'paf_layer':i, 'paf_layerwise_per_batch_val_loss': l})
	for i, l in enumerate(layerwise_mean_conf_loss):
		wandb.log({'conf_layer':i,'conf_layerwise_per_batch_val_loss': l})
	"""


def train_n_epochs(model, dataloaders, tot_epochs, device, optimizers, schedulers, model_info, test=False):
	min_val_loss, min_paf_val_loss, min_conf_val_loss = math.inf, math.inf, math.inf
	for epoch in range(tot_epochs):
		train_epoch(model, optimizers, schedulers, dataloaders['train'], device, test=test)
		
		epoch_val_loss, epoch_paf_val_loss, epoch_conf_val_loss = val_epoch(model, dataloaders['val'], device, epoch, test=test)
		if (epoch_val_loss < min_val_loss):
			min_val_loss = epoch_val_loss
		else:
			print('val loss did not decrease after previous epoch. Time to terminate and tweak the hyperparameters')
			break
		if (epoch_paf_val_loss < min_paf_val_loss):
			min_paf_val_loss = epoch_paf_val_loss
		if (epoch_conf_val_loss < min_conf_val_loss):
                	min_conf_val_loss = epoch_conf_val_loss
		dict_to_save = {}
		dict_to_save['model_state_dict'] = model.state_dict()
		for i, opt in enumerate(optimizers):
			dict_to_save['opt_{}_state_dict'.format(i)] = opt.state_dict()
		for i, sch in enumerate(schedulers):
			if (sch):
				dict_to_save['sch_{}_state_dict'.format(i)] = sch.state_dict()
		saved_file_path = './models/{}_{}_{}_epoch_{}.pt'.format(model_info, model.paf_stages, model.conf_stages, epoch)
		torch.save(dict_to_save, saved_file_path)
		print(saved_file_path)
